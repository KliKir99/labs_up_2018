{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "second.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kmka1hIPU3v",
        "colab_type": "text"
      },
      "source": [
        "Вторая версия эксперимента, Кирилл Климук"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RoqGAuQQbFs",
        "colab_type": "text"
      },
      "source": [
        "Пути к данным:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuumqRBNP_JC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_TRAIN_CSV = 'drive/My Drive/for_graduate/DS kaggle 2019/train.csv'\n",
        "PATH_TO_TRAIN_IMAGES = 'drive/My Drive/for_graduate/DS kaggle 2019/train_images'\n",
        "PATH_TO_TEST_IMAGES = 'drive/My Drive/for_graduate/DS kaggle 2019/test_images'\n",
        "PATH_TO_SUBMISSION_CSV = 'drive/My Drive/for_graduate/DS kaggle 2019/sample_submission.csv'\n",
        "PATH_TO_LOG_FILE = 'drive/My Drive/for_graduate/DS kaggle 2019/log.txt'\n",
        "\n",
        "log_file = open(PATH_TO_LOG_FILE, 'w+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzvxNBJBQoGC",
        "colab_type": "text"
      },
      "source": [
        "Необходимые импорты:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS5j_KNmPU30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "import os\n",
        "from torchvision import transforms\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltCrAU8cILTS",
        "colab_type": "text"
      },
      "source": [
        "GPU vs CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbXGwM5BH1q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cpu')\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    torch.set_default_tensor_type('torch.cuda.FloatTensor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0EDYAur98em",
        "colab_type": "text"
      },
      "source": [
        "Высчитываем данные из .csv файла в датафрейм:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX6PXydLPU39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(PATH_TO_TRAIN_CSV, index_col = 'Image_Label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8bm8L1M-Gb2",
        "colab_type": "text"
      },
      "source": [
        "Архитектура нейронной сети:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4pd-TA5PU4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class preUNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = torch.nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3, padding = 1)\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 3, padding = 1)\n",
        "        self.act2 = torch.nn.ReLU()\n",
        "\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        \n",
        "        \n",
        "        self.conv3 = torch.nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, padding = 1)\n",
        "        self.act3 = torch.nn.ReLU()\n",
        "        \n",
        "        \n",
        "        self.final_conv = torch.nn.Conv2d(in_channels = 32, out_channels = 5, kernel_size = 1, padding = 0)\n",
        "        self.sigm = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.act2(x)\n",
        "\n",
        "        #print('before pooling: ', x.shape)\n",
        "\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        #print('after pooling: ', x.shape)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.act3(x)\n",
        "        \n",
        "        x = self.final_conv(x)\n",
        "        \n",
        "        x = self.sigm(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G9wwqa_Xz64",
        "colab_type": "text"
      },
      "source": [
        "Эталонная маска по классам (полученная из входного .csv файла) (для функции CrossEntropyLoss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTZJiM04PU4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_perfect_class_mask_by_photo_name(photo_name):\n",
        "    \n",
        "    mask = (torch.zeros((1, 350 * 525))).long()\n",
        "\n",
        "    mask[:][:] = 4\n",
        "\n",
        "    patterns = ['Fish', 'Flower', 'Gravel', 'Sugar']\n",
        "    \n",
        "    def update_perfect_tensor_by_pattern(answer, pattern):\n",
        "        needed_str = df['EncodedPixels'][photo_name + '_' + pattern]\n",
        "        if type(needed_str) == str:\n",
        "            val = patterns.index(pattern)\n",
        "            needed_list = needed_str.split(' ')\n",
        "            for i in range(0, len(needed_list), 2):\n",
        "                number_of_starting_pixel = (int(needed_list[i]) // 2100 // 4) * 525 +\\\n",
        "                                            int(needed_list[i]) % 2100 // 4\n",
        "                count = min(int(needed_list[i + 1]) // 4, 350 * 525 - number_of_starting_pixel)\n",
        "                answer[0][number_of_starting_pixel : number_of_starting_pixel + count] = val\n",
        "            \n",
        "    \n",
        "    update_perfect_tensor_by_pattern(mask, 'Fish')\n",
        "    update_perfect_tensor_by_pattern(mask, 'Flower')\n",
        "    update_perfect_tensor_by_pattern(mask, 'Gravel')\n",
        "    update_perfect_tensor_by_pattern(mask, 'Sugar')\n",
        "    \n",
        "    return mask.reshape((350, 525))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CpnOaJeSd-Q",
        "colab_type": "text"
      },
      "source": [
        "Создание экземпляра нейронной сети и оптимизатор:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4srQRlTYPU4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "instance = preUNet()\n",
        "\n",
        "optimizer = torch.optim.Adam(instance.parameters(), lr = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q8_3XFqPU4c",
        "colab_type": "text"
      },
      "source": [
        "Лосс функция - pixel-wise cross-entropy loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsUk1LNfBihm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD9B3bAMPU4s",
        "colab_type": "text"
      },
      "source": [
        "Процесс тренировки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh2exin4PU4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "TRAIN_DATA_SET_SIZE = 20\n",
        "NUMBER_OF_ERAS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XDeVag0PU40",
        "colab_type": "code",
        "outputId": "a638054c-96d3-4abb-c6a5-d5e33510e670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epoch_list = []\n",
        "loss_values_list = []\n",
        "\n",
        "photoname_train_list = os.listdir(PATH_TO_TRAIN_IMAGES)\n",
        "photoname_train_list = photoname_train_list[:TRAIN_DATA_SET_SIZE]\n",
        "\n",
        "print(photoname_train_list)\n",
        "\n",
        "start_learning = time.time()\n",
        "\n",
        "for epoch in range(NUMBER_OF_ERAS):\n",
        "\n",
        "    print('epoch #' + str(epoch) + ' is started, time = ' + str(time.time() - start_learning) + ' s')\n",
        "\n",
        "    permutation = np.random.permutation(len(photoname_train_list))\n",
        "    \n",
        "    #batch\n",
        "    for batch_index in range(0, len(photoname_train_list), BATCH_SIZE):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #batch_list = photoname_train_list[batch_index : batch_index + BATCH_SIZE]\n",
        "        batch_list = [photoname_train_list[i] for i in permutation[batch_index : batch_index + BATCH_SIZE]]\n",
        "        \n",
        "        # perfect\n",
        "        perfect_tensor = torch.zeros((len(batch_list), 350, 525))\n",
        "        perfect_tensor = perfect_tensor.long() ## why\n",
        "        \n",
        "        for i, photoname in enumerate(batch_list):\n",
        "            \n",
        "            print(i, photoname, file = log_file)\n",
        "\n",
        "            perfect_tensor[i] = get_perfect_class_mask_by_photo_name(photoname)\n",
        "\n",
        "            \n",
        "        print('perfect - done!', file=log_file)\n",
        "            \n",
        "        #predicted\n",
        "        predicted_tensor_args = torch.zeros((len(batch_list), 3, 700, 1050))\n",
        "        \n",
        "        for i, photoname in enumerate(batch_list):\n",
        "            \n",
        "            print(i, photoname, file=log_file)\n",
        "            im = Image.open(PATH_TO_TRAIN_IMAGES + '/' + photoname)\n",
        "            im = im.resize((1050, 700))\n",
        "            \n",
        "            tens_operator = transforms.ToTensor()\n",
        "            \n",
        "            predicted_tensor_args[i][0] = tens_operator(im)[0]\n",
        "            predicted_tensor_args[i][1] = tens_operator(im)[1]\n",
        "            predicted_tensor_args[i][2] = tens_operator(im)[2]\n",
        "\n",
        "            im.close()\n",
        "            \n",
        "        print('predicted args - done!', file=log_file)\n",
        "        \n",
        "        predicted_tensor_values = instance.forward(predicted_tensor_args)\n",
        "\n",
        "        #print(predicted_tensor_values)\n",
        "        #print(perfect_tensor)\n",
        "        \n",
        "        print('predicted values - done!', file=log_file)\n",
        "        \n",
        "        loss_value = loss(predicted_tensor_values, perfect_tensor)\n",
        "\n",
        "        print('loss_value = ', loss_value)\n",
        "\n",
        "        epoch_list.append(epoch)\n",
        "        loss_values_list.append(loss_value)\n",
        "        \n",
        "        print('loss - done!', file=log_file)\n",
        "\n",
        "        loss_value.backward()\n",
        "        \n",
        "        print('backward - done!', file=log_file)\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        print('optimizer step - done!', file=log_file)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['d24e67f.jpg', 'd22eb33.jpg', 'd2041d7.jpg', 'd265d38.jpg', 'd21b166.jpg', 'd27e37b.jpg', 'd2b4399.jpg', 'd2a42ee.jpg', 'd2e0f14.jpg', 'd2a540d.jpg', 'd2b72aa.jpg', 'd2eb9fe.jpg', 'd29a30a.jpg', 'd2e7aa7.jpg', 'd2c4532.jpg', 'd2c5a99.jpg', 'd314a09.jpg', 'd31f11f.jpg', 'd31af98.jpg', 'd35d04f.jpg']\n",
            "epoch #0 is started, time = 0.0004253387451171875 s\n",
            "loss_value =  tensor(1.5485, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #1 is started, time = 18.023037910461426 s\n",
            "loss_value =  tensor(1.5479, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #2 is started, time = 36.04644274711609 s\n",
            "loss_value =  tensor(1.5509, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #3 is started, time = 54.161821365356445 s\n",
            "loss_value =  tensor(1.5530, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #4 is started, time = 72.22925615310669 s\n",
            "loss_value =  tensor(1.5551, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #5 is started, time = 90.32185864448547 s\n",
            "loss_value =  tensor(1.5535, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #6 is started, time = 108.3658185005188 s\n",
            "loss_value =  tensor(1.5493, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #7 is started, time = 126.34287810325623 s\n",
            "loss_value =  tensor(1.5502, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #8 is started, time = 144.36174631118774 s\n",
            "loss_value =  tensor(1.5390, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #9 is started, time = 162.35889220237732 s\n",
            "loss_value =  tensor(1.5429, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #10 is started, time = 180.32300519943237 s\n",
            "loss_value =  tensor(1.5470, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #11 is started, time = 198.4366238117218 s\n",
            "loss_value =  tensor(1.5425, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #12 is started, time = 216.51388025283813 s\n",
            "loss_value =  tensor(1.5405, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #13 is started, time = 234.48228788375854 s\n",
            "loss_value =  tensor(1.5396, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #14 is started, time = 252.48686838150024 s\n",
            "loss_value =  tensor(1.5334, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #15 is started, time = 270.50573682785034 s\n",
            "loss_value =  tensor(1.5288, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #16 is started, time = 288.58593559265137 s\n",
            "loss_value =  tensor(1.5211, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #17 is started, time = 306.67479038238525 s\n",
            "loss_value =  tensor(1.5163, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #18 is started, time = 324.7844030857086 s\n",
            "loss_value =  tensor(1.5119, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #19 is started, time = 342.8558967113495 s\n",
            "loss_value =  tensor(1.4940, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #20 is started, time = 360.944287776947 s\n",
            "loss_value =  tensor(1.4894, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #21 is started, time = 379.101735830307 s\n",
            "loss_value =  tensor(1.4812, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #22 is started, time = 397.29557728767395 s\n",
            "loss_value =  tensor(1.4795, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #23 is started, time = 415.364408493042 s\n",
            "loss_value =  tensor(1.4691, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #24 is started, time = 433.46303629875183 s\n",
            "loss_value =  tensor(1.4667, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #25 is started, time = 451.7086491584778 s\n",
            "loss_value =  tensor(1.4648, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #26 is started, time = 469.80143642425537 s\n",
            "loss_value =  tensor(1.4533, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #27 is started, time = 487.9118411540985 s\n",
            "loss_value =  tensor(1.4559, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #28 is started, time = 506.12617802619934 s\n",
            "loss_value =  tensor(1.4600, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #29 is started, time = 524.3055944442749 s\n",
            "loss_value =  tensor(1.4439, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #30 is started, time = 542.3932130336761 s\n",
            "loss_value =  tensor(1.4477, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #31 is started, time = 560.4195280075073 s\n",
            "loss_value =  tensor(1.4349, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #32 is started, time = 578.4895870685577 s\n",
            "loss_value =  tensor(1.4309, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #33 is started, time = 596.5466842651367 s\n",
            "loss_value =  tensor(1.4268, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #34 is started, time = 614.5144114494324 s\n",
            "loss_value =  tensor(1.4249, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #35 is started, time = 632.5277042388916 s\n",
            "loss_value =  tensor(1.4272, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #36 is started, time = 650.4876339435577 s\n",
            "loss_value =  tensor(1.4302, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #37 is started, time = 668.4753148555756 s\n",
            "loss_value =  tensor(1.4305, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #38 is started, time = 686.5241119861603 s\n",
            "loss_value =  tensor(1.4315, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #39 is started, time = 704.5740237236023 s\n",
            "loss_value =  tensor(1.4260, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #40 is started, time = 722.6614017486572 s\n",
            "loss_value =  tensor(1.4326, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #41 is started, time = 740.6487393379211 s\n",
            "loss_value =  tensor(1.4360, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #42 is started, time = 758.8462545871735 s\n",
            "loss_value =  tensor(1.4353, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #43 is started, time = 776.9636611938477 s\n",
            "loss_value =  tensor(1.4362, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #44 is started, time = 795.0231895446777 s\n",
            "loss_value =  tensor(1.4304, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #45 is started, time = 813.0264406204224 s\n",
            "loss_value =  tensor(1.4403, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #46 is started, time = 831.0738928318024 s\n",
            "loss_value =  tensor(1.4357, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #47 is started, time = 849.0506408214569 s\n",
            "loss_value =  tensor(1.4309, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #48 is started, time = 867.0747168064117 s\n",
            "loss_value =  tensor(1.4338, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #49 is started, time = 885.1223611831665 s\n",
            "loss_value =  tensor(1.4317, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #50 is started, time = 903.1514823436737 s\n",
            "loss_value =  tensor(1.4407, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #51 is started, time = 921.0852773189545 s\n",
            "loss_value =  tensor(1.4273, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #52 is started, time = 939.0437843799591 s\n",
            "loss_value =  tensor(1.4336, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #53 is started, time = 957.0151746273041 s\n",
            "loss_value =  tensor(1.4260, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #54 is started, time = 974.9197010993958 s\n",
            "loss_value =  tensor(1.4260, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #55 is started, time = 992.905207157135 s\n",
            "loss_value =  tensor(1.4334, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #56 is started, time = 1010.8460378646851 s\n",
            "loss_value =  tensor(1.4419, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #57 is started, time = 1028.794260263443 s\n",
            "loss_value =  tensor(1.4341, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #58 is started, time = 1046.8547520637512 s\n",
            "loss_value =  tensor(1.4375, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #59 is started, time = 1064.8959443569183 s\n",
            "loss_value =  tensor(1.4338, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #60 is started, time = 1082.8775305747986 s\n",
            "loss_value =  tensor(1.4423, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #61 is started, time = 1100.839868068695 s\n",
            "loss_value =  tensor(1.4438, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #62 is started, time = 1118.8258986473083 s\n",
            "loss_value =  tensor(1.4352, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #63 is started, time = 1136.9465019702911 s\n",
            "loss_value =  tensor(1.4336, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #64 is started, time = 1154.9970543384552 s\n",
            "loss_value =  tensor(1.4279, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #65 is started, time = 1173.1495039463043 s\n",
            "loss_value =  tensor(1.4297, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #66 is started, time = 1191.2266895771027 s\n",
            "loss_value =  tensor(1.4254, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #67 is started, time = 1209.3274965286255 s\n",
            "loss_value =  tensor(1.4321, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #68 is started, time = 1227.3894801139832 s\n",
            "loss_value =  tensor(1.4220, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #69 is started, time = 1245.3934407234192 s\n",
            "loss_value =  tensor(1.4242, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #70 is started, time = 1263.3780024051666 s\n",
            "loss_value =  tensor(1.4132, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #71 is started, time = 1281.3555445671082 s\n",
            "loss_value =  tensor(1.4314, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #72 is started, time = 1299.3350358009338 s\n",
            "loss_value =  tensor(1.4210, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #73 is started, time = 1317.3053004741669 s\n",
            "loss_value =  tensor(1.4180, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #74 is started, time = 1335.241673707962 s\n",
            "loss_value =  tensor(1.4143, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #75 is started, time = 1353.1502437591553 s\n",
            "loss_value =  tensor(1.4158, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #76 is started, time = 1371.1200120449066 s\n",
            "loss_value =  tensor(1.4141, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #77 is started, time = 1389.0414350032806 s\n",
            "loss_value =  tensor(1.4109, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #78 is started, time = 1406.9765360355377 s\n",
            "loss_value =  tensor(1.4076, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #79 is started, time = 1424.87043094635 s\n",
            "loss_value =  tensor(1.4057, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #80 is started, time = 1442.8461525440216 s\n",
            "loss_value =  tensor(1.4032, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #81 is started, time = 1460.786229133606 s\n",
            "loss_value =  tensor(1.4057, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #82 is started, time = 1478.7058463096619 s\n",
            "loss_value =  tensor(1.4009, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #83 is started, time = 1496.600598335266 s\n",
            "loss_value =  tensor(1.4016, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #84 is started, time = 1514.523593902588 s\n",
            "loss_value =  tensor(1.4065, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #85 is started, time = 1532.543285369873 s\n",
            "loss_value =  tensor(1.4021, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #86 is started, time = 1550.5296092033386 s\n",
            "loss_value =  tensor(1.4048, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #87 is started, time = 1568.545350074768 s\n",
            "loss_value =  tensor(1.4010, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #88 is started, time = 1586.4955003261566 s\n",
            "loss_value =  tensor(1.4025, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #89 is started, time = 1604.4720361232758 s\n",
            "loss_value =  tensor(1.4086, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #90 is started, time = 1622.4058678150177 s\n",
            "loss_value =  tensor(1.4073, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #91 is started, time = 1640.3766973018646 s\n",
            "loss_value =  tensor(1.4142, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #92 is started, time = 1658.3686745166779 s\n",
            "loss_value =  tensor(1.4109, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #93 is started, time = 1676.4067425727844 s\n",
            "loss_value =  tensor(1.4109, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #94 is started, time = 1694.3475427627563 s\n",
            "loss_value =  tensor(1.4107, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #95 is started, time = 1712.2648150920868 s\n",
            "loss_value =  tensor(1.4113, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #96 is started, time = 1730.1964826583862 s\n",
            "loss_value =  tensor(1.4028, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #97 is started, time = 1748.0909786224365 s\n",
            "loss_value =  tensor(1.4021, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #98 is started, time = 1766.1128559112549 s\n",
            "loss_value =  tensor(1.3967, grad_fn=<NllLoss2DBackward>)\n",
            "epoch #99 is started, time = 1784.0556151866913 s\n",
            "loss_value =  tensor(1.3955, grad_fn=<NllLoss2DBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3MceDiQrkPP",
        "colab_type": "text"
      },
      "source": [
        "Построим график loss-функции от числа эпох:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTwhGAlbrm_H",
        "colab_type": "code",
        "outputId": "e7dce1b0-4ddc-4bbc-c9b0-84113a99714f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch_list, loss_values_list)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl7OgN8YYL2dBb4wxXs6C3hhjvNz/B91RdcfhQT0bAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QljLN9acAgpG",
        "colab_type": "text"
      },
      "source": [
        "Процесс тестирования:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohvasl2gfw35",
        "colab_type": "text"
      },
      "source": [
        "Выходной .csv файл:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbknB8a4PU5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(PATH_TO_SUBMISSION_CSV, 'w+')\n",
        "f.close()\n",
        "\n",
        "submission_df = pd.DataFrame(columns = ['Image_Label', 'EncodedPixels'])\n",
        "submission_df = submission_df.set_index('Image_Label')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtcjIZrZgBW5",
        "colab_type": "text"
      },
      "source": [
        "Вспомогательные функции:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwMpOJW0gB2n",
        "colab_type": "text"
      },
      "source": [
        "Перевод выходного тензора в предсказанную маску паттернов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPpIkGHPmQ-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_predicted_mask_to_pattern_mask(tens):\n",
        "\n",
        "    if tens.shape != torch.Size([1, 5, 350, 525]):\n",
        "      raise ValueError('incorrect input shape!')\n",
        "\n",
        "    return torch.argmax(tens, dim = 1).resize_(350, 525)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3oN-YQzgQ0E",
        "colab_type": "text"
      },
      "source": [
        "Получение строк для .csv файла из маски паттернов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoFrHra6zA4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_strings_from_pattern_mask(pattern_mask):\n",
        "\n",
        "    def get_pattern_str(pattern_val_in_mask):\n",
        "      answer_list = []\n",
        "      count = 0\n",
        "      for h in range(350):\n",
        "        for w in range(525):\n",
        "          if pattern_mask[h][w] == pattern_val_in_mask:\n",
        "            count += 1\n",
        "          else:\n",
        "            if count != 0:\n",
        "              answer_list.append(str(525 * h + w - count))\n",
        "              answer_list.append(str(count))\n",
        "              count = 0\n",
        "      if count != 0:\n",
        "        answer_list.append(str(525 * 350 - count))\n",
        "        answer_list.append(str(count))\n",
        "      \n",
        "      return ' '.join(answer_list)\n",
        "\n",
        "    #fish, flower, gravel, sugar\n",
        "    return get_pattern_str(0), get_pattern_str(1), get_pattern_str(2), get_pattern_str(3)  \n",
        "              \n",
        "              \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9xjDtJMjyOK",
        "colab_type": "text"
      },
      "source": [
        "Сам процесс тестирования:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBiAW3Dkj52M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUMBER_OF_PROCESSED_TEST_IMAGES = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8noCEnyfrH-",
        "colab_type": "code",
        "outputId": "4b37c3db-105b-44fd-f8e0-5b804ee491ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "photoname_test_list = os.listdir(PATH_TO_TEST_IMAGES)\n",
        "photoname_test_list = photoname_test_list[:NUMBER_OF_PROCESSED_TEST_IMAGES]\n",
        "\n",
        "for test_image_photoname in photoname_test_list:\n",
        "\n",
        "    print(test_image_photoname)\n",
        "\n",
        "    im = Image.open(PATH_TO_TEST_IMAGES + '/' + test_image_photoname)\n",
        "    im = im.resize((1050, 700))\n",
        "\n",
        "    to_tensor = transforms.ToTensor()\n",
        "\n",
        "    predicted_tensor_from_nn = instance.forward(to_tensor(im).resize_(1, 3, 700, 1050))\n",
        "\n",
        "    #print(predicted_tensor_from_nn[0][0])\n",
        "    #print(predicted_tensor_from_nn[0][1])\n",
        "    #print(predicted_tensor_from_nn[0][2])\n",
        "    #print(predicted_tensor_from_nn[0][3])\n",
        "    #print(predicted_tensor_from_nn[0][4])\n",
        "\n",
        "    #print(nn_predicted_mask_to_pattern_mask(predicted_tensor_from_nn))\n",
        "\n",
        "    fish_str, flower_str, gravel_str, sugar_str = get_strings_from_pattern_mask(nn_predicted_mask_to_pattern_mask(predicted_tensor_from_nn))\n",
        "\n",
        "    submission_df.loc[test_image_photoname + '_Fish'] = fish_str\n",
        "    submission_df.loc[test_image_photoname + '_Flower'] = flower_str\n",
        "    submission_df.loc[test_image_photoname + '_Gravel'] = gravel_str\n",
        "    submission_df.loc[test_image_photoname + '_Sugar'] = sugar_str\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bc3ca7f.jpg\n",
            "bbd680d.jpg\n",
            "bbe5085.jpg\n",
            "bc7ea95.jpg\n",
            "bc354be.jpg\n",
            "bc9017f.jpg\n",
            "bcf66d6.jpg\n",
            "bce3c05.jpg\n",
            "bd237a7.jpg\n",
            "bcf4c08.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB58bppLj9OZ",
        "colab_type": "text"
      },
      "source": [
        "Записать получившийся выходной датафрейм в .csv файл:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wogSwpZ_fo1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df.to_csv(PATH_TO_SUBMISSION_CSV)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}